{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM-OoKV-tZve",
        "outputId": "2b9c0abd-cc38-4ea2-ed90-5e67809e0259",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2024.12.2)\n",
            "Requirement already satisfied: unsloth_zoo>=2024.11.8 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2024.12.1)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.0.28.post3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.9.2)\n",
            "Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.46.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.1.1)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.12.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.26.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (0.20.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth) (24.12.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth) (11.0.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vZx54kg-82KC",
        "outputId": "7ea0d125-68bf-4972-a0ef-8f76aaa5baa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xccsysRtPQg",
        "outputId": "4eead3a1-c716-4638-813e-68955e83f3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import Dataset\n",
        "from unsloth import FastLanguageModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model for inference"
      ],
      "metadata": {
        "id": "JOQ05Nt6NaOc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-r9UkIOFtPQi"
      },
      "outputs": [],
      "source": [
        "HF_TOKEN = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMkqLiUctPQi",
        "outputId": "b5c635ee-4779-4466-d7b5-f625ed16fd31",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.12.2: Fast Qwen2 patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.12.2 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2ForCausalLM(\n",
              "      (model): Qwen2Model(\n",
              "        (embed_tokens): Embedding(151936, 1536, padding_idx=151665)\n",
              "        (layers): ModuleList(\n",
              "          (0-27): 28 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1536, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=1536, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1536, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=256, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1536, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=256, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1536, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=1536, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1536, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=8960, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1536, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=8960, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8960, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=1536, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"RichardNooooh/Qwen2.5-1.5B-AF-Augmented\",\n",
        "    max_seq_length = 2048,\n",
        "    load_in_4bit = False,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "tokenizer.padding_side = \"left\" # for batch processing\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get sentiment"
      ],
      "metadata": {
        "id": "ns1qGtRFM-ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "3iMmqdJZOYYS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def get_sentiments(review_text):\n",
        "    system_prompt = (\n",
        "        \"You are an emotionally intelligent agent designed to evaluate various sentiments of a given piece of text. \"\n",
        "        \"Given the following review for an Amazon item, please score the text for each sentiment type between 0.0 and 1.0 \"\n",
        "        \"(inclusive), where 0.0 is the complete absence of that sentiment and 1.0 is a strong indication of that sentiment.\"\n",
        "    )\n",
        "    schema = {\n",
        "        \"name\": \"sentiment_scores\",\n",
        "        \"description\": \"Sentiments of the given text scored between 0.0 to 1.0 (inclusive)\",\n",
        "        \"strict\": True,\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"satisfaction\": {\"type\": \"number\", \"description\": \"Contentment or fulfillment with the product or service.\"},\n",
        "                \"gratitude\": {\"type\": \"number\", \"description\": \"Thankfulness or appreciation.\"},\n",
        "                \"trust\": {\"type\": \"number\", \"description\": \"Confidence in the product or brand.\"},\n",
        "                \"disappointment\": {\"type\": \"number\", \"description\": \"Unmet expectations or dissatisfaction.\"},\n",
        "                \"frustration\": {\"type\": \"number\", \"description\": \"Annoyance or irritation experienced.\"},\n",
        "                \"confusion\": {\"type\": \"number\", \"description\": \"Lack of clarity or understanding.\"},\n",
        "                \"fear\": {\"type\": \"number\", \"description\": \"Concern or worry about potential risks.\"},\n",
        "                \"regret\": {\"type\": \"number\", \"description\": \"Wishing one hadn't made the purchase or choice.\"},\n",
        "                \"indifference\": {\"type\": \"number\", \"description\": \"Lack of strong feelings or interest.\"},\n",
        "                \"informative\": {\"type\": \"number\", \"description\": \"Providing information about the product without strong feelings.\"},\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"satisfaction\",\n",
        "                \"gratitude\",\n",
        "                \"trust\",\n",
        "                \"disappointment\",\n",
        "                \"frustration\",\n",
        "                \"confusion\",\n",
        "                \"fear\",\n",
        "                \"regret\",\n",
        "                \"indifference\",\n",
        "                \"informative\",\n",
        "            ],\n",
        "            \"additionalProperties\": False,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # OpenAI API Call\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": review_text},\n",
        "            ],\n",
        "            functions=[{\"name\": schema[\"name\"], \"parameters\": schema[\"schema\"]}],\n",
        "            function_call={\"name\": schema[\"name\"]},\n",
        "            temperature=0.0,\n",
        "            max_tokens=300,\n",
        "        )\n",
        "        # Extract the function_call arguments\n",
        "        sentiment_scores = json.loads(response.choices[0].message.function_call.arguments)\n",
        "        return sentiment_scores\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "7ezI1TNqNBX0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Keyword"
      ],
      "metadata": {
        "id": "kD8KZP9HNCFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def get_keywords(review_text):\n",
        "    system_prompt = \"You are a helpful assistant designed to analyze Amazon \"+\\\n",
        "                    \"reviews. Your task is to extract up to 10 concise keywords \"+\\\n",
        "                    \"and phrases that represent the product's features, benefits, \"+\\\n",
        "                    \"or issues from the provided text. Only include keywords directly \"+\\\n",
        "                    \"found in the text.\"\n",
        "\n",
        "    schema = {\n",
        "        \"name\": \"get_keywords\",\n",
        "        \"strict\": True,\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "            \"problem_keywords\": {\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\n",
        "                \"type\": \"string\"\n",
        "                },\n",
        "                \"description\": \"Keywords identifying specific issues and features mentioned in the review.\"\n",
        "            }\n",
        "            },\n",
        "            \"required\": [\n",
        "            \"problem_keywords\"\n",
        "            ],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # OpenAI API Call\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": review_text},\n",
        "            ],\n",
        "            functions=[{\"name\": schema[\"name\"], \"parameters\": schema[\"schema\"]}],\n",
        "            function_call={\"name\": schema[\"name\"]},\n",
        "            temperature=0.0,\n",
        "            max_tokens=300,\n",
        "        )\n",
        "        # Extract the function_call arguments\n",
        "        sentiment_scores = json.loads(response.choices[0].message.function_call.arguments)\n",
        "        return sentiment_scores\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "0t2ahiivNEhI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct input Data"
      ],
      "metadata": {
        "id": "niax1jlBO8Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(item_title, average_review, review_titles, review_texts):\n",
        "    \"\"\"\n",
        "    Prepare the dataset for the SLM, combining item title, average review, sentiments, and keywords.\n",
        "    \"\"\"\n",
        "    dataset = f\"{item_title}\\n\"\n",
        "    dataset += f\"Average Rating: {average_review}\\n\\n\"  # Add the average review\n",
        "\n",
        "    for i, (review_title, review_text) in enumerate(zip(review_titles, review_texts), start=1):\n",
        "        if not review_title or not review_text:\n",
        "            continue  # Skip empty reviews\n",
        "\n",
        "        # Get sentiment scores\n",
        "        sentiments = get_sentiments(review_text)\n",
        "        if sentiments is None:\n",
        "            sentiments = {}\n",
        "\n",
        "        # Get keywords\n",
        "        keywords_result = get_keywords(review_text)\n",
        "        if not isinstance(keywords_result, dict) or \"problem_keywords\" not in keywords_result:\n",
        "            raise ValueError(\"get_keywords must return a dictionary with a 'problem_keywords' key\")\n",
        "\n",
        "        # Extract the keywords list\n",
        "        keywords = keywords_result[\"problem_keywords\"]\n",
        "        if not isinstance(keywords, list):\n",
        "            raise ValueError(\"'problem_keywords' must be a list of strings\")\n",
        "\n",
        "        # Format sentiments and keywords\n",
        "        sentiments_str = \", \".join(f\"{k}: {v:.1f}\" for k, v in sentiments.items())\n",
        "        keywords_str = \", \".join(keywords[:5])  # Limit to 5 keywords\n",
        "\n",
        "        # Append the formatted review\n",
        "        dataset += (\n",
        "            f\"{i}-star review:\\n\"\n",
        "            f\"- Review Title: {review_title}\\n\"\n",
        "            f\"- Review Text: {review_text}\\n\"\n",
        "            f\"- Keywords: {keywords_str}\\n\"\n",
        "            f\"- Sentiment scores: {sentiments_str}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "WugmoMPOPZ6R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1T4XDz6IR1R4",
        "outputId": "b6a96236-7b56-4be6-b5a7-22feaae29654"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.9.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define your SYSTEM_PROMPT\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a helpful assistant for a business. \"\n",
        "    + \"You are given a set of Amazon reviews for a given item, one for each rating out of 5, \"\n",
        "    + \"and tasked with providing actionable feedback to help improve this item. \"\n",
        "    + \"Please format your response into concise sentences, one for each actionable feedback. \"\n",
        "    + \"Place each feedback on a bulletpoint.\"\n",
        ")\n",
        "\n",
        "# Define the preprocess_function\n",
        "def preprocess_function(examples):\n",
        "    texts, labels = examples[\"text\"], examples[\"labels\"]\n",
        "\n",
        "    # Create conversation structure for all texts at once\n",
        "    conversations = [\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": texts}\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    # Apply chat template to all conversations at once\n",
        "    formatted_data = tokenizer.apply_chat_template(conversations, tokenize=False)\n",
        "\n",
        "    return {\"text\": formatted_data, \"labels\": labels}\n",
        "\n",
        "def process_feedback(item_title, average_review, review_titles, review_texts):\n",
        "    try:\n",
        "        # Step 1: Prepare the dataset\n",
        "        dataset = prepare_dataset(item_title, average_review, review_titles, review_texts)\n",
        "\n",
        "        # Step 2: Preprocess the dataset for the model\n",
        "        preprocessed = preprocess_function({\"text\": dataset, \"labels\": \"\"})  # No list wrapping\n",
        "        processed_text = preprocessed[\"text\"]\n",
        "        if \"error\" in preprocessed:\n",
        "            return f\"Preprocessing Error: {preprocessed['error']}\"\n",
        "\n",
        "        # Step 3: Tokenize and move to GPU\n",
        "        test_in = tokenizer(processed_text, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "\n",
        "        # Step 4: Generate feedback using the model\n",
        "        output_ids = model.generate(**test_in, max_new_tokens=200)\n",
        "        test_out = tokenizer.decode(output_ids[0][test_in[\"input_ids\"].shape[-1]:])\n",
        "\n",
        "        # Step 5: Clean and return the generated feedback\n",
        "        return test_out.removeprefix(\"<|im_start|>assistant\").removesuffix(\"<|im_end|>\")\n",
        "    except Exception as e:\n",
        "        # Capture and return error details\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=lambda item_title, average_review, review_title_1, review_text_1, review_title_2, review_text_2,\n",
        "             review_title_3, review_text_3, review_title_4, review_text_4, review_title_5, review_text_5:\n",
        "        process_feedback(\n",
        "            item_title,\n",
        "            average_review,\n",
        "            [review_title_1, review_title_2, review_title_3, review_title_4, review_title_5],\n",
        "            [review_text_1, review_text_2, review_text_3, review_text_4, review_text_5]\n",
        "        ),\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Amazon Item Title\", placeholder=\"Enter the Amazon item title here\"),\n",
        "        gr.Textbox(label=\"Average Review\", placeholder=\"Enter the average star rating here\", lines=1),\n",
        "        gr.Textbox(label=\"Review Title 1\", placeholder=\"Enter review 1 title here\", lines=1),\n",
        "        gr.Textbox(label=\"Review 1\", placeholder=\"Enter review 1 text here\", lines=3),\n",
        "        gr.Textbox(label=\"Review Title 2\", placeholder=\"Enter review 2 title here\", lines=1),\n",
        "        gr.Textbox(label=\"Review 2\", placeholder=\"Enter review 2 text here\", lines=3),\n",
        "        gr.Textbox(label=\"Review Title 3\", placeholder=\"Enter review 3 title here\", lines=1),\n",
        "        gr.Textbox(label=\"Review 3\", placeholder=\"Enter review 3 text here\", lines=3),\n",
        "        gr.Textbox(label=\"Review Title 4\", placeholder=\"Enter review 4 title here\", lines=1),\n",
        "        gr.Textbox(label=\"Review 4\", placeholder=\"Enter review 4 text here\", lines=3),\n",
        "        gr.Textbox(label=\"Review Title 5\", placeholder=\"Enter review 5 title here\", lines=1),\n",
        "        gr.Textbox(label=\"Review 5\", placeholder=\"Enter review 5 text here\", lines=3),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Feedback\", lines=20),\n",
        "    title=\"Amazon Review Feedback Generator\",\n",
        "    description=\"Input the Amazon item title, average review, and up to 5 reviews to generate actionable feedback with sentiment analysis and keywords.\",\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "eJjer9QcByJW",
        "outputId": "2b5a681d-fa66-4708-9e22-b305edbb5669"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://eb82c3bb9248a8e293.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eb82c3bb9248a8e293.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}